# small-business-closure-prediction-and-insight
**폐업 예측 모델과 소상공인 상권 인사이트 시스템 개발** 

---

### 프로젝트 개요 
- **문제 정의**  
    - 코로나19 이후 소상공인의 폐업률이 급증하며, 지역·상권별 매출 격차 확대  
    - 창업·폐업 관련 데이터가 여러 기관에 분산되어 있어 정보 접근성 부족  
- **목표**  
    1. 실시간 데이터, 매출 및 업종 데이터를 활용한 대시보드 구현
    2. 행정안전부, 스마트 치안 빅데이터 플랫폼 데이터를 기반으로 폐업 예측 모델을 개발하여 MLflow를 통한 모델 서빙 및 API 배포
    3. 소상공인과 신규 창업자 등을 대상으로 하는 맞춤형 질의응답 챗봇 개발   
    4. 위의 모든 기능을 포함한 웹 서비스 구현 및 도메인 연결
- **기간/인원**: 2025.03.17 ~ 2025.05.23 (3개월) / 5명  
- **담당 역할**  
    - API 수집 파이프라인 개발
    - 데이터 전처리 및 피처 엔지니어링  
    - ML 모델 개발 및 실험
    - Streamlit 기반 웹 서비스 구현   
- **사용 기술**  
    - 분석/개발: Databricks, PySpark, Delta Lake, SQL, scikit-learn, pandas, NumPy  
    - 시각화/웹: Matplotlib, Seaborn, Streamlit, Nginx
    - 협업 도구: GitHub, Slack  

--- 

### 사용 데이터 
- **서울 열린 데이터 광장** | 실시간 상권현황, 실시간 인구현황, 상권별 매출 데이터 
- **행정안전부 인허가 데이터** | 사업장명, 인허가일자, 폐업일자, 업종 등 
- **스마트 치안 빅데이터 플랫폼** | 폐업률, 생존율, 소비 특성, 평균 영업 기간, 상권 활성화 지수 
- **소상공인시장진흥공단** | 상권 정보, 상가 업소, 지원 사업  
- **행정안전부 도로명주소 API** | 주소 → 시도, 시군구, 법정동 매핑 

---

### 분석 절차 
#### 1. 데이터 수집 
- Databricks Job Scheduler와 PySpark로 실시간 데이터 자동 수집 
- 행안부 도로명주소 API를 이용하여 행정구역 보완  
- Bronze/Silver/Gold 구조의 Delta Lake에 저장하여 추후 분석·모델링에 활용  

#### 2. 데이터 전처리 (행정안전부 인허가 데이터)  
1. 폐업일자 기준 필터링 (2020년 이후 폐업 또는 미폐업 사업장만 포함) 
2. 분석에 필요한 컬럼 추출  
3. 행정구역 정보 매핑  
    - EPSG:5174 → EPSG:4326 좌표계 변환 
    - 좌표 컬럼 존재 시 shp 파일로 시도/시군구/법정동 매핑 
    - 좌표 컬럼 미존재 시 행안부 도로명주소 API로 수집한 시도/시군구/법정동 정보 매핑  
4. 사업장명 정제 (불필요 단어·특수문자 제거, 표기 통일)  
5. 업종 대분류 필터링 (폐업 건수 ≤ 100 제외) 
6. 운영기간 범주화  

#### 3. 피처 엔지니어링  
- 범주형 변수 라벨 인코딩 / 원핫 인코딩  
- 사업장명 임베딩 벡터 생성  
- 프렌차이즈 여부 파생변수 생성 

#### 4. 모델링   
##### **1차 실험**  
- 데이터 규모: 약 100만건 
- 샘플링 절차
    - 전체 데이터에서 train/test 90:10 비율로 계층적 샘플링 (기준: 폐업유무, 업종 대분류)  
    - test 데이터는 실제 분포 유지, train 데이터에서 폐업유무 기준 100만 건 샘플링  
- features: 시도, 시군구, 법정동, 업종 소분류, 업종 대분류, 운영기간  
- 범주형 변수: 라벨 인코딩 적용 
- 모델: RandomForest, XGBoost 비교  
- 클래스 불균형 처리: 클래스 불균형/언더샘플링/오버샘플링 기법 성능 비교 후 선정  
- 결과: 오버샘플링 방식으로 클래스 불균형 처리 진행, ROC-AUC, f1-score, recall 지표 기준으로 XGBoost 모델 선정 
##### **2차 실험**  
- 데이터 규모: 약 630만 건 (전처리 작업 후 전체 데이터) 
- 샘플링 절차
    - train/test 80:20 비율로 계층적 샘플링
    - train 데이터 축소 없이 전체 사용  
- features: 시도, 시군구, 업종 대분류, 운영기간 
- 범주형 변수: 원핫 인코딩  
- 모델: XGBoost 단일 
- 결과: 1차 실험과 비교하여 성능이 크게 향상하진 않았으며, 유지 수준에 머무름 
##### **추가 실험**    
- 데이터 규모: 약 70만 건 (서버리스 환경 한계로 축소)
- 샘플링 절차: 
    - train/test 90:10 비율로 계층적 샘플링 적용 (기준: 폐업유무, 업종 대분류)
    - train 데이터에서 폐업 유무 기준 70만건 샘플링 
- 범주형 변수: 원핫 인코딩 
- 샘플링 방식: 오버샘플링  
- 추가 피처: 사업장명 임베딩 벡터, 프렌차이즈 여부 파생변수 
- 모델: XGBoost 
- 목적: 파생변수 추가가 예측 성능에 미치는 영향 확인  
- 결과: recall/f1-score에서 약간의 차이는 있었지만, ROC-AUC 기준으로는 기본 피처가 가장 우수 

---  

### 웹 서비스 구현 
- Streamlit 기반 웹 서비스 개발
- Databricks 대시보드 및 REST API 엔드포인트 연동
- Nginx + HTTPS 도메인(asacdataanalysis.co.kr) 배포

--- 

### 결과물 
- [웹 시연 영상](https://drive.google.com/file/d/1bIU9HW_oHcoDe9Y-D2o9LXvAtu7P-KUD/view?usp=drive_link)  

![웹 서비스 메인 페이지](https://github.com/seoyoung-J/small-business-closure-prediction-and-insight/blob/main/StreamlitApp/assets/images/main_page.png?raw=true
)

---

### 참고 
- 본 레포지토리는 프로젝트에서 담당한 주요 역할을 바탕으로 코드 구조 및 파일을 재정리한 버전입니다. 
- 원본 협업 저장소: [asac_7_dataanalysis](https://github.com/da-analysis/asac_7_dataanalysis.git) 

